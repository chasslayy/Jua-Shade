{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chasslayy/Jua-Shade/blob/main/JuaShade_SkinTone_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0340b2b8",
      "metadata": {
        "id": "0340b2b8"
      },
      "source": [
        "# JuaShade ‚Äì Skin Tone Classification (Google Colab Template)\n",
        "\n",
        "This notebook is a starter template for **Chastity (Chasslayy)** to build a skin tone classifier\n",
        "using 5 classes:\n",
        "\n",
        "- `tan`\n",
        "- `medium`\n",
        "- `deep`\n",
        "- `brown`\n",
        "- `light`\n",
        "\n",
        "It assumes the following folder structure in Colab:\n",
        "\n",
        "```text\n",
        "/content/\n",
        "  data/\n",
        "    raw/\n",
        "      train/\n",
        "        tan/\n",
        "        medium/\n",
        "        deep/\n",
        "        brown/\n",
        "        light/\n",
        "```\n",
        "\n",
        "Upload your images into the matching folders, then run the cells in order.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x08-nFB10LOd"
      },
      "id": "x08-nFB10LOd"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Eb7w49JX2CZ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "afdf0f4b-a4ae-4f28-a93d-01e3ffcc83ce"
      },
      "id": "Eb7w49JX2CZ-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "IXQHjlCXzo2h"
      },
      "id": "IXQHjlCXzo2h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00ff089c",
      "metadata": {
        "id": "00ff089c"
      },
      "outputs": [],
      "source": [
        "# 1. Imports & basic setup\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Base directory for your dataset in Colab\n",
        "TRAIN_DIR = \"/content/data/raw/train\"\n",
        "\n",
        "# Your 5 skin tone classes\n",
        "CLASSES = ['tan', 'medium', 'deep', 'brown', 'light']\n",
        "\n",
        "print(\"‚úÖ Using train directory:\", TRAIN_DIR)\n",
        "print(\"‚úÖ Classes:\", CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72a6c1e4",
      "metadata": {
        "id": "72a6c1e4"
      },
      "outputs": [],
      "source": [
        "# 2. Count how many images per tone\n",
        "\n",
        "def count_images_in_folder(folder):\n",
        "    if not os.path.exists(folder):\n",
        "        return 0\n",
        "    return len([f for f in os.listdir(folder)\n",
        "                if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "\n",
        "print(\"üìä Training samples per class:\\n\")\n",
        "class_counts = {}\n",
        "for tone in CLASSES:\n",
        "    tone_path = os.path.join(TRAIN_DIR, tone)\n",
        "    n = count_images_in_folder(tone_path)\n",
        "    class_counts[tone] = n\n",
        "    if n == 0:\n",
        "        print(f\"  ‚ö†Ô∏è {tone}: 0 images (or folder missing: {tone_path})\")\n",
        "    else:\n",
        "        print(f\"  {tone}: {n} images\")\n",
        "\n",
        "# Save a small text summary\n",
        "os.makedirs(\"reports\", exist_ok=True)\n",
        "summary_lines = [\"Skin Tone Dataset Summary\\n\",\n",
        "                 f\"Train directory: {TRAIN_DIR}\\n\\n\",\n",
        "                 \"Classes and counts:\\n\"]\n",
        "for tone, n in class_counts.items():\n",
        "    summary_lines.append(f\"  {tone}: {n} images\\n\")\n",
        "\n",
        "summary_text = \"\".join(summary_lines)\n",
        "print(\"\\n\" + summary_text)\n",
        "\n",
        "with open(\"reports/dataset_summary.txt\", \"w\") as f:\n",
        "    f.write(summary_text)\n",
        "\n",
        "print(\"‚úÖ Saved reports/dataset_summary.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ae7bc3",
      "metadata": {
        "id": "39ae7bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "50bbd77b-0113-453e-e705-34d34bae6631"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TRAIN_DIR' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3217335061.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mshow_sample_images_per_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'TRAIN_DIR' is not defined"
          ]
        }
      ],
      "source": [
        "# 3. Show one sample image from each class\n",
        "\n",
        "def read_image(path):\n",
        "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "def show_sample_images_per_class(base_dir, classes, n_cols=5):\n",
        "    plt.figure(figsize=(3 * n_cols, 4))\n",
        "\n",
        "    for idx, tone in enumerate(classes):\n",
        "        tone_path = os.path.join(base_dir, tone)\n",
        "        if not os.path.exists(tone_path):\n",
        "            print(f\"‚ö†Ô∏è Skipping {tone}, folder not found.\")\n",
        "            continue\n",
        "\n",
        "        files = [f for f in os.listdir(tone_path)\n",
        "                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if len(files) == 0:\n",
        "            print(f\"‚ö†Ô∏è No images in {tone_path}\")\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(tone_path, files[0])\n",
        "        img = read_image(img_path)\n",
        "\n",
        "        plt.subplot(1, n_cols, idx + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(tone)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_sample_images_per_class(TRAIN_DIR, CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d252f180",
      "metadata": {
        "id": "d252f180"
      },
      "outputs": [],
      "source": [
        "# 4. Build TensorFlow datasets from folders\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 8\n",
        "SEED = 1337\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    class_names=CLASSES,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMG_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=SEED,\n",
        "    validation_split=0.2,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    class_names=CLASSES,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMG_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=SEED,\n",
        "    validation_split=0.2,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(\"Classes (from dataset):\", class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5ab5ed1",
      "metadata": {
        "id": "c5ab5ed1"
      },
      "outputs": [],
      "source": [
        "# 5. Optimize dataset performance\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def configure_for_performance(ds):\n",
        "    ds = ds.cache()\n",
        "    ds = ds.shuffle(100, reshuffle_each_iteration=True)\n",
        "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train_ds = configure_for_performance(train_ds)\n",
        "val_ds = configure_for_performance(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "688f60e5",
      "metadata": {
        "id": "688f60e5"
      },
      "outputs": [],
      "source": [
        "# 6. Build a transfer learning model (MobileNetV2)\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=IMG_SIZE + (3,),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False  # fine-tune later if needed\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.05),\n",
        "])\n",
        "\n",
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "inputs = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = tf.keras.layers.Dense(len(CLASSES), activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf78d478",
      "metadata": {
        "id": "bf78d478"
      },
      "outputs": [],
      "source": [
        "# 7. Train the model\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3724e4d1",
      "metadata": {
        "id": "3724e4d1"
      },
      "outputs": [],
      "source": [
        "# 8. Evaluate model and show sample predictions\n",
        "\n",
        "loss, acc = model.evaluate(val_ds)\n",
        "print(f\"Validation loss: {loss:.4f}, accuracy: {acc:.4f}\")\n",
        "\n",
        "# Show a few sample predictions\n",
        "class_names = CLASSES\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "for images, labels in val_ds.take(1):\n",
        "    preds = model.predict(images)\n",
        "    pred_labels = tf.argmax(preds, axis=1)\n",
        "\n",
        "    for i in range(min(5, images.shape[0])):\n",
        "        ax = plt.subplot(1, 5, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        true_label = class_names[labels[i].numpy()]\n",
        "        pred_label = class_names[pred_labels[i].numpy()]\n",
        "        plt.title(f\"T: {true_label}\\nP: {pred_label}\")\n",
        "        plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/content/data/raw/train\"\n",
        "\n",
        "# Verify folders exist\n",
        "print(\"‚úÖ Folders found:\")\n",
        "for folder in sorted(os.listdir(base_path)):\n",
        "    folder_path = os.path.join(base_path, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        print(f\"- {folder}\")\n"
      ],
      "metadata": {
        "id": "cwu7UUKu52P4"
      },
      "id": "cwu7UUKu52P4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Base path for your training images\n",
        "base_path = \"/content/data/raw/train\"\n",
        "\n",
        "# Create a list of your tone folders\n",
        "tone_folders = sorted(os.listdir(base_path))\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "for i, tone in enumerate(tone_folders):\n",
        "    folder_path = os.path.join(base_path, tone)\n",
        "    if os.path.isdir(folder_path):\n",
        "        images = os.listdir(folder_path)\n",
        "        if len(images) > 0:\n",
        "            # Pick one random image from the folder\n",
        "            img_path = os.path.join(folder_path, random.choice(images))\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            plt.subplot(1, len(tone_folders), i + 1)\n",
        "            plt.imshow(img)\n",
        "            plt.title(tone, fontsize=12)\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2GqRmYh16TzF"
      },
      "id": "2GqRmYh16TzF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BASELINE MODEL (simple MobileNetV2)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load base model (MobileNetV2)\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "base_model.trainable = False  # Freeze for baseline\n",
        "\n",
        "# Build model\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(5, activation='softmax')  # 5 skin tone classes\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "EPOCHS = 5\n",
        "history_baseline = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "oUxtAgv6AuD2"
      },
      "id": "oUxtAgv6AuD2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True  # unfreeze backbone\n",
        "\n",
        "# Optionally: only fine-tune last few layers\n",
        "for layer in base_model.layers[:-30]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "EPOCHS = 5\n",
        "history_finetune = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS\n",
        ")\n"
      ],
      "metadata": {
        "id": "ni0qB1r_A1E7"
      },
      "id": "ni0qB1r_A1E7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot accuracy\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_baseline.history['accuracy'], label='Train (Baseline)')\n",
        "plt.plot(history_baseline.history['val_accuracy'], label='Val (Baseline)')\n",
        "plt.plot(history_finetune.history['accuracy'], label='Train (Advanced)')\n",
        "plt.plot(history_finetune.history['val_accuracy'], label='Val (Advanced)')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_baseline.history['loss'], label='Train (Baseline)')\n",
        "plt.plot(history_baseline.history['val_loss'], label='Val (Baseline)')\n",
        "plt.plot(history_finetune.history['loss'], label='Train (Adv_\n"
      ],
      "metadata": {
        "id": "ChumJvGMBXM4"
      },
      "id": "ChumJvGMBXM4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}